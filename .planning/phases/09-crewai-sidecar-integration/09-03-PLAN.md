---
phase: 09-crewai-sidecar-integration
plan: 03
type: execute
wave: 2
depends_on: ["09-02"]
files_modified:
  - plugins/daily-news-digest/crew/crew.py
  - plugins/daily-news-digest/crew/config/agents.yaml
  - plugins/daily-news-digest/crew/config/tasks.yaml
  - docker-compose.yml
  - deploy/k8s/sidecar-deployment.yaml
autonomous: true

must_haves:
  truths:
    - "daily-news-digest plugin has a CrewAI crew with researcher, writer, and reviewer agents"
    - "crew.py exports create_crew(settings) factory function matching sidecar contract"
    - "Agent and task definitions are in YAML config files, not hardcoded in Python"
    - "docker-compose up starts sidecar alongside Go app, both sharing same Redis"
    - "K8s manifest deploys sidecar as separate Deployment from Go app with independent scaling"
  artifacts:
    - path: "plugins/daily-news-digest/crew/crew.py"
      provides: "CrewAI @CrewBase class with researcher/writer/reviewer agents and create_crew factory"
      contains: "create_crew"
    - path: "plugins/daily-news-digest/crew/config/agents.yaml"
      provides: "Agent role, goal, backstory definitions for researcher, writer, reviewer"
      contains: "researcher"
    - path: "plugins/daily-news-digest/crew/config/tasks.yaml"
      provides: "Task descriptions and expected outputs for research, write, review steps"
      contains: "research_task"
    - path: "docker-compose.yml"
      provides: "Sidecar service definition sharing Redis with Go app"
      contains: "first-sip-sidecar"
    - path: "deploy/k8s/sidecar-deployment.yaml"
      provides: "K8s Deployment + Service for sidecar with HPA, liveness, readiness probes"
      contains: "sidecar"
  key_links:
    - from: "plugins/daily-news-digest/crew/crew.py"
      to: "sidecar/executor.py"
      via: "create_crew(settings) factory function contract"
      pattern: "def create_crew"
    - from: "plugins/daily-news-digest/crew/crew.py"
      to: "plugins/daily-news-digest/crew/config/agents.yaml"
      via: "CrewBase agents_config path reference"
      pattern: "agents_config"
    - from: "plugins/daily-news-digest/crew/crew.py"
      to: "plugins/daily-news-digest/crew/config/tasks.yaml"
      via: "CrewBase tasks_config path reference"
      pattern: "tasks_config"
    - from: "docker-compose.yml"
      to: "sidecar/Dockerfile"
      via: "build context for sidecar service"
      pattern: "build.*sidecar"
---

<objective>
Create the daily-news-digest CrewAI workflow (agents + tasks YAML, crew class), add sidecar to docker-compose for local development, and add a Kubernetes deployment manifest for production-grade independent scaling.

Purpose: This is the final wiring that makes the end-to-end pipeline real. Plan 01 built the Go side (publish requests, consume results). Plan 02 built the Python sidecar (consume requests, execute crews, publish results). This plan fills the remaining pieces: the actual CrewAI workflow that does the AI work, the docker-compose entry so developers can run everything locally, and the K8s manifest so the sidecar scales independently in production.

Output: Working CrewAI crew for daily-news-digest plugin, docker-compose sidecar service, and K8s deployment manifest.
</objective>

<execution_context>
@/Users/jim/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jim/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-crewai-sidecar-integration/09-RESEARCH.md
@.planning/phases/09-crewai-sidecar-integration/09-02-SUMMARY.md
@plugins/daily-news-digest/plugin.yaml
@plugins/daily-news-digest/settings.schema.json
@docker-compose.yml
</context>

<tasks>

<task type="auto">
  <name>Task 1: CrewAI workflow for daily-news-digest plugin</name>
  <files>plugins/daily-news-digest/crew/crew.py, plugins/daily-news-digest/crew/config/agents.yaml, plugins/daily-news-digest/crew/config/tasks.yaml</files>
  <action>
Remove the existing `plugins/daily-news-digest/crew/.gitkeep` placeholder file.

Create `plugins/daily-news-digest/crew/config/agents.yaml` with three agents:

```yaml
researcher:
  role: "Senior News Research Analyst"
  goal: "Discover and analyze breaking news in {topics} to identify stories relevant to user interests"
  backstory: >
    You are an experienced news analyst with expertise in {topics}.
    You excel at finding high-quality sources, fact-checking claims,
    and identifying stories that matter to discerning readers.
  verbose: true

writer:
  role: "News Digest Writer"
  goal: "Transform research findings into concise, engaging news summaries"
  backstory: >
    You are a skilled writer who crafts compelling news digests.
    You distill complex topics into clear, actionable summaries
    that respect the reader's time while delivering full context.
  verbose: true

reviewer:
  role: "Editorial Quality Reviewer"
  goal: "Ensure news digest meets quality standards for accuracy, clarity, and relevance"
  backstory: >
    You are a meticulous editor who ensures every digest is
    factually accurate, well-structured, and free of bias.
    You catch errors that others miss.
  verbose: false
```

The `{topics}` placeholders are interpolated by CrewAI from the `inputs` dict passed to `kickoff_async`.

Create `plugins/daily-news-digest/crew/config/tasks.yaml` with three sequential tasks:

```yaml
research_task:
  description: >
    Research breaking news in these topics: {topics}.
    Find 3-5 high-quality stories from reputable sources.
    For each story, note: headline, source, key facts, why it matters.
  expected_output: >
    JSON array of stories with fields: headline, source_url,
    summary (2-3 sentences), relevance_score (1-10)

write_task:
  description: >
    Using the research findings, write a news digest.
    Format: Brief intro paragraph, then 3-5 story summaries.
    Each summary: headline, 2-3 sentence explanation, source credit.
    Tone: Professional but conversational. Max 500 words total.
    Summary length preference: {summary_length}.
  expected_output: >
    Markdown-formatted news digest ready for display

review_task:
  description: >
    Review the news digest for:
    - Factual accuracy (check claims against research)
    - Clarity (no jargon, clear explanations)
    - Formatting (proper Markdown, consistent style)
    - Bias detection (neutral tone maintained)
    If issues found, return revised version. If acceptable, approve as-is.
  expected_output: >
    Final approved news digest in Markdown format, with quality score (1-10)
```

The `{topics}` and `{summary_length}` placeholders come from user settings (matching the fields in `settings.schema.json`).

Create `plugins/daily-news-digest/crew/crew.py`:

```python
"""Daily News Digest CrewAI workflow.

Implements the researcher -> writer -> reviewer multi-agent pattern.
Loaded dynamically by the sidecar executor via the create_crew() factory.
"""
import os
from pathlib import Path
from crewai import Agent, Task, Crew, Process
from crewai.project import CrewBase, agent, task, crew


@CrewBase
class NewsDigestCrew:
    """Multi-agent crew for generating daily news digests."""

    agents_config = str(Path(__file__).parent / "config" / "agents.yaml")
    tasks_config = str(Path(__file__).parent / "config" / "tasks.yaml")

    @agent
    def researcher(self) -> Agent:
        return Agent(config=self.agents_config["researcher"], verbose=True)

    @agent
    def writer(self) -> Agent:
        return Agent(config=self.agents_config["writer"], verbose=True)

    @agent
    def reviewer(self) -> Agent:
        return Agent(config=self.agents_config["reviewer"], verbose=False)

    @task
    def research_task(self) -> Task:
        return Task(config=self.tasks_config["research_task"], agent=self.researcher())

    @task
    def write_task(self) -> Task:
        return Task(
            config=self.tasks_config["write_task"],
            agent=self.writer(),
            context=[self.research_task()],
        )

    @task
    def review_task(self) -> Task:
        return Task(
            config=self.tasks_config["review_task"],
            agent=self.reviewer(),
            context=[self.write_task()],
        )

    @crew
    def crew(self) -> Crew:
        return Crew(
            agents=self.agents,
            tasks=self.tasks,
            process=Process.sequential,
            verbose=True,
        )


def create_crew(settings: dict) -> Crew:
    """Factory function called by sidecar executor.

    This is the contract between plugin crew definitions and the sidecar:
    every plugin's crew/crew.py must export create_crew(settings) -> Crew.

    Args:
        settings: User plugin settings (topics, summary_length, etc.)

    Returns:
        Configured Crew instance ready for kickoff_async(inputs=settings).
    """
    return NewsDigestCrew().crew()
```

Key details:
- `agents_config` and `tasks_config` use absolute paths via `Path(__file__).parent` so they work regardless of working directory (important when loaded by sidecar from a different cwd)
- `create_crew(settings)` is the factory function matching the contract in `sidecar/executor.py`'s `_load_crew` method
- Tasks chain via `context=[]` parameter: write_task depends on research_task, review_task depends on write_task (sequential pipeline)
- `Process.sequential` ensures tasks run in order
- No LangChain imports (CrewAI is independent of LangChain per research)
  </action>
  <verify>
Verify Python syntax: `python3 -c "import ast; ast.parse(open('plugins/daily-news-digest/crew/crew.py').read()); print('Syntax OK')"`. Verify YAML syntax: `python3 -c "import yaml; yaml.safe_load(open('plugins/daily-news-digest/crew/config/agents.yaml')); yaml.safe_load(open('plugins/daily-news-digest/crew/config/tasks.yaml')); print('YAML OK')"`. Verify factory function exists: `grep 'def create_crew' plugins/daily-news-digest/crew/crew.py`. Verify .gitkeep removed: `test ! -f plugins/daily-news-digest/crew/.gitkeep && echo 'gitkeep removed' || echo 'gitkeep still exists'`.
  </verify>
  <done>daily-news-digest has a complete CrewAI crew with three agents (researcher, writer, reviewer) defined in YAML config files and a Python crew class with create_crew() factory matching the sidecar executor contract. Tasks chain sequentially via context dependencies.</done>
</task>

<task type="auto">
  <name>Task 2: Docker Compose sidecar service and K8s deployment manifest</name>
  <files>docker-compose.yml, deploy/k8s/sidecar-deployment.yaml</files>
  <action>
Update `docker-compose.yml` to add the sidecar service. Keep all existing services (postgres, redis, asynqmon) unchanged. Add:

```yaml
  sidecar:
    build:
      context: .
      dockerfile: sidecar/Dockerfile
    container_name: first-sip-sidecar
    environment:
      REDIS_URL: redis://redis:6379
      PLUGIN_DIR: /app/plugins
      CREW_TIMEOUT_SECONDS: "300"
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
    ports:
      - "8000:8000"
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ./plugins:/app/plugins:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health/live"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 10s
```

Key details:
- Uses Redis service hostname `redis` (same network as other services)
- Mounts `./plugins` read-only so crew definitions are available without rebuilding
- Passes `OPENAI_API_KEY` from host env (CrewAI agents need LLM access). Uses `${OPENAI_API_KEY:-}` to default to empty string if not set (sidecar will still start, just fail on actual crew execution)
- Health check uses curl against /health/live
- `depends_on` waits for Redis health check before starting
- Port 8000 exposed for health endpoint access during development

Create `deploy/k8s/sidecar-deployment.yaml` with K8s resources for independent sidecar scaling:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: first-sip-sidecar
  labels:
    app: first-sip-sidecar
    component: crewai-executor
spec:
  replicas: 1
  selector:
    matchLabels:
      app: first-sip-sidecar
  template:
    metadata:
      labels:
        app: first-sip-sidecar
        component: crewai-executor
    spec:
      containers:
        - name: sidecar
          image: first-sip-sidecar:latest
          ports:
            - containerPort: 8000
          env:
            - name: REDIS_URL
              valueFrom:
                secretKeyRef:
                  name: first-sip-secrets
                  key: redis-url
            - name: OPENAI_API_KEY
              valueFrom:
                secretKeyRef:
                  name: first-sip-secrets
                  key: openai-api-key
            - name: PLUGIN_DIR
              value: "/app/plugins"
            - name: CREW_TIMEOUT_SECONDS
              value: "300"
          livenessProbe:
            httpGet:
              path: /health/live
              port: 8000
            initialDelaySeconds: 10
            periodSeconds: 15
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /health/ready
              port: 8000
            initialDelaySeconds: 15
            periodSeconds: 10
            failureThreshold: 3
          resources:
            requests:
              cpu: "250m"
              memory: "512Mi"
            limits:
              cpu: "2"
              memory: "2Gi"
---
apiVersion: v1
kind: Service
metadata:
  name: first-sip-sidecar
  labels:
    app: first-sip-sidecar
spec:
  selector:
    app: first-sip-sidecar
  ports:
    - port: 8000
      targetPort: 8000
  type: ClusterIP
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: first-sip-sidecar
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: first-sip-sidecar
  minReplicas: 1
  maxReplicas: 5
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
```

Key K8s details:
- Separate Deployment from Go app (CREW-07: independent scaling)
- HPA scales 1-5 replicas based on CPU (CrewAI is CPU-bound during LLM calls)
- Higher memory limits (2Gi) because CrewAI + Python runtime is heavier than Go
- Liveness probe hits /health/live, readiness probe hits /health/ready (checks Redis)
- Secrets referenced from `first-sip-secrets` (not hardcoded)
- ClusterIP service (internal only, no external ingress needed â€” communication is via Redis Streams)
  </action>
  <verify>
Verify docker-compose YAML syntax: `python3 -c "import yaml; yaml.safe_load(open('docker-compose.yml')); print('docker-compose OK')"`. Verify K8s YAML syntax: `python3 -c "import yaml; list(yaml.safe_load_all(open('deploy/k8s/sidecar-deployment.yaml'))); print('K8s YAML OK')"`. Verify sidecar service exists in compose: `grep 'first-sip-sidecar' docker-compose.yml`. Verify existing services preserved: `grep 'first-sip-db' docker-compose.yml && grep 'first-sip-redis' docker-compose.yml && grep 'first-sip-asynqmon' docker-compose.yml`.
  </verify>
  <done>docker-compose.yml has sidecar service sharing Redis with Go app, mounting plugins directory, and passing OPENAI_API_KEY. K8s manifest has separate Deployment + Service + HPA for independent sidecar scaling with proper health probes and resource limits.</done>
</task>

</tasks>

<verification>
- crew.py has valid Python syntax and exports `create_crew(settings) -> Crew`
- agents.yaml defines researcher, writer, reviewer with role/goal/backstory
- tasks.yaml defines research_task, write_task, review_task with description/expected_output
- Task YAML uses `{topics}` and `{summary_length}` placeholders matching settings.schema.json fields
- docker-compose.yml is valid YAML with sidecar service added and all existing services preserved
- K8s sidecar-deployment.yaml has Deployment, Service, and HPA as separate documents
- K8s Deployment uses /health/live for liveness and /health/ready for readiness
- K8s HPA targets CPU utilization for scaling CrewAI workloads
- Sidecar is NOT in same Deployment as Go app (independent scaling verified)
</verification>

<success_criteria>
- daily-news-digest plugin has a complete CrewAI workflow with three agents and sequential task pipeline
- crew.py factory function matches sidecar executor contract
- Agent/task definitions are in YAML (not hardcoded Python), supporting plugin author customization
- docker-compose starts sidecar alongside existing services for local development
- K8s manifest enables independent sidecar scaling in production
- End-to-end pipeline is architecturally complete: Go publishes -> Redis Streams -> Python consumes -> CrewAI executes -> Python publishes result -> Redis Streams -> Go consumes
</success_criteria>

<output>
After completion, create `.planning/phases/09-crewai-sidecar-integration/09-03-SUMMARY.md`
</output>
