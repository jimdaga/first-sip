---
phase: 09-crewai-sidecar-integration
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - sidecar/pyproject.toml
  - sidecar/main.py
  - sidecar/worker.py
  - sidecar/executor.py
  - sidecar/models.py
  - sidecar/Dockerfile
autonomous: true

must_haves:
  truths:
    - "FastAPI sidecar process starts and /health/live returns 200"
    - "/health/ready returns 200 when Redis is connected, 503 when Redis is down"
    - "Worker loop consumes messages from plugin:requests stream via crewai-workers consumer group"
    - "After processing, worker publishes result to plugin:results stream and ACKs the request"
    - "Long-running workflows timeout after configurable duration without leaking threads"
  artifacts:
    - path: "sidecar/pyproject.toml"
      provides: "Python project config with crewai, fastapi, redis, uvicorn dependencies"
      contains: "crewai"
    - path: "sidecar/main.py"
      provides: "FastAPI app with /health/live, /health/ready, and background worker startup"
      contains: "health/live"
    - path: "sidecar/worker.py"
      provides: "Redis Streams consumer loop with two-phase pending+new pattern"
      contains: "xreadgroup"
    - path: "sidecar/executor.py"
      provides: "CrewExecutor with asyncio.timeout wrapper around kickoff_async"
      contains: "asyncio.timeout"
    - path: "sidecar/models.py"
      provides: "Pydantic models for PluginRequest and PluginResult stream messages"
      contains: "PluginRequest"
    - path: "sidecar/Dockerfile"
      provides: "Multi-stage Docker build for production sidecar image"
      contains: "uvicorn"
  key_links:
    - from: "sidecar/worker.py"
      to: "redis"
      via: "redis.asyncio xreadgroup consumer group"
      pattern: "xreadgroup"
    - from: "sidecar/worker.py"
      to: "sidecar/executor.py"
      via: "CrewExecutor.execute_with_timeout call"
      pattern: "execute_with_timeout"
    - from: "sidecar/main.py"
      to: "sidecar/worker.py"
      via: "asyncio.create_task on startup lifespan"
      pattern: "create_task"
    - from: "sidecar/executor.py"
      to: "crewai"
      via: "crew.kickoff_async wrapped in asyncio.timeout"
      pattern: "kickoff_async"
---

<objective>
Build the FastAPI Python sidecar service that consumes plugin execution requests from Redis Streams, runs CrewAI workflows with timeout protection, and publishes results back.

Purpose: This is the Python half of the two-stream communication pattern. It provides the runtime environment where CrewAI multi-agent workflows execute, isolated from the Go application and independently scalable. The sidecar handles health probes for Kubernetes, consumes work from `plugin:requests`, and publishes results to `plugin:results`.

Output: Complete `sidecar/` directory with FastAPI app, Redis Streams worker loop, CrewAI executor with timeout wrapper, Pydantic message models, and production Dockerfile.
</objective>

<execution_context>
@/Users/jim/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jim/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-crewai-sidecar-integration/09-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Pydantic models, FastAPI app with health endpoints, and project config</name>
  <files>sidecar/pyproject.toml, sidecar/models.py, sidecar/main.py</files>
  <action>
Create `sidecar/pyproject.toml` with:
- `[project]` section: name = "first-sip-sidecar", version = "0.1.0", requires-python = ">=3.11,<3.14"
- Dependencies: `crewai>=1.9.3`, `fastapi>=0.115.0`, `uvicorn[standard]>=0.32.0`, `redis>=6.1.0`
- `[project.scripts]` section: `sidecar = "main:run"` for convenience
- `[build-system]` section: requires = ["hatchling"], build-backend = "hatchling.build"

Create `sidecar/models.py` with Pydantic v2 models:
- `PluginRequest(BaseModel)`: `plugin_run_id: str`, `plugin_name: str`, `user_id: int`, `settings: dict[str, Any]`
- `PluginResult(BaseModel)`: `plugin_run_id: str`, `status: Literal["completed", "failed"]`, `output: str | None = None`, `error: str | None = None`
- Constants matching Go side: `STREAM_PLUGIN_REQUESTS = "plugin:requests"`, `STREAM_PLUGIN_RESULTS = "plugin:results"`, `GROUP_NAME = "crewai-workers"`, `SCHEMA_VERSION = "v1"`

Create `sidecar/main.py` with:
- FastAPI app using lifespan context manager (NOT deprecated `on_event`):
  ```python
  from contextlib import asynccontextmanager

  @asynccontextmanager
  async def lifespan(app: FastAPI):
      # Startup: create Redis client, start worker task
      app.state.redis = redis.from_url(settings.redis_url)
      app.state.worker_task = asyncio.create_task(consume_plugin_requests(app.state.redis, settings))
      yield
      # Shutdown: cancel worker, close Redis
      app.state.worker_task.cancel()
      await app.state.redis.aclose()
  ```
- `Settings` class using pydantic-settings or simple env var reads: `redis_url` (default "redis://localhost:6379"), `plugin_dir` (default "../plugins"), `crew_timeout_seconds` (default 300), `consumer_name` (default hostname via `socket.gethostname()`)
- `GET /health/live` -> returns `{"status": "alive"}` always 200
- `GET /health/ready` -> pings Redis, returns `{"status": "ready", "redis": "connected"}` on success, returns 503 `{"status": "not_ready", "error": ...}` on failure. Use a SEPARATE Redis client for health checks (not the worker's client) to avoid blocking XREADGROUP exhausting pool — create `app.state.health_redis` in lifespan startup
- `run()` function: calls `uvicorn.run("main:app", host="0.0.0.0", port=8000)`
- Import `consume_plugin_requests` from `worker` module (will be created in Task 2)

Use `logging` stdlib with structured format. Read Redis URL from `REDIS_URL` env var. Read plugin dir from `PLUGIN_DIR` env var. Read timeout from `CREW_TIMEOUT_SECONDS` env var.
  </action>
  <verify>
From the sidecar directory, verify Python syntax: `python3 -c "import ast; ast.parse(open('sidecar/models.py').read()); ast.parse(open('sidecar/main.py').read()); print('Syntax OK')"`. Verify pyproject.toml is valid TOML: `python3 -c "import tomllib; tomllib.load(open('sidecar/pyproject.toml', 'rb')); print('TOML OK')"`.
  </verify>
  <done>pyproject.toml declares all Python dependencies. models.py has Pydantic PluginRequest/PluginResult with stream constants matching Go side. main.py has FastAPI app with /health/live, /health/ready (separate Redis client), lifespan startup/shutdown, and env-based configuration.</done>
</task>

<task type="auto">
  <name>Task 2: Redis Streams worker loop, CrewAI executor with timeout, and Dockerfile</name>
  <files>sidecar/worker.py, sidecar/executor.py, sidecar/Dockerfile</files>
  <action>
Create `sidecar/worker.py` with:
- `consume_plugin_requests(redis_client: redis.Redis, settings)` async function — the main worker loop:
  1. Create consumer group `crewai-workers` on `plugin:requests` stream with `xgroup_create(mkstream=True)`. Catch `ResponseError` and ignore if "BUSYGROUP" in message.
  2. Two-phase consumer loop (runs forever until cancelled):
     - **Phase 1 — Pending recovery:** `xreadgroup` with streams `{STREAM_PLUGIN_REQUESTS: '0'}` (re-read unACKed messages from PEL), count=10, block=100ms. Process each message if any.
     - **Phase 2 — New messages:** `xreadgroup` with streams `{STREAM_PLUGIN_REQUESTS: '>'}` (new messages only), count=10, block=5000ms. Process each message if any.
  3. On any exception in the loop: log error, sleep 1 second, continue (never crash the loop)
  4. On `asyncio.CancelledError`: log shutdown message, re-raise to exit cleanly

- `process_message(redis_client, msg_id, msg_data, settings)` async function:
  1. Parse `payload` field from msg_data (handle both `bytes` and `str` keys — redis-py returns bytes keys by default with `decode_responses=False`, but with `from_url` it depends on config). Use `msg_data.get("payload") or msg_data.get(b"payload")` pattern for safety, then decode if bytes.
  2. Validate with `PluginRequest.model_validate_json(payload_str)` — if validation fails, log error, ACK the message (bad message, don't retry), return
  3. Log: "Processing plugin_run_id={req.plugin_run_id} plugin={req.plugin_name}"
  4. Create `CrewExecutor(timeout_seconds=settings.crew_timeout_seconds, plugin_dir=settings.plugin_dir)`
  5. Call `result = await executor.execute(req)` — returns PluginResult
  6. Publish result: `await redis_client.xadd(STREAM_PLUGIN_RESULTS, {"payload": result.model_dump_json(), "schema_version": SCHEMA_VERSION})`
  7. ACK request: `await redis_client.xack(STREAM_PLUGIN_REQUESTS, GROUP_NAME, msg_id)`
  8. Log: "Completed plugin_run_id={req.plugin_run_id} status={result.status}"
  9. On exception during processing: log error, do NOT ACK (message stays in PEL for retry)

Create `sidecar/executor.py` with:
- `CrewExecutor` class:
  - `__init__(self, timeout_seconds: int = 300, plugin_dir: str = "../plugins")` — stores config
  - `execute(self, request: PluginRequest) -> PluginResult` async method:
    1. Load crew for plugin: call `self._load_crew(request.plugin_name, request.settings)`
    2. If crew is None (plugin not found or no crew/ directory): return `PluginResult(plugin_run_id=..., status="failed", error="Plugin crew not found: {name}")`
    3. Execute with timeout wrapper:
       ```python
       try:
           async with asyncio.timeout(self.timeout_seconds):
               result = await crew.kickoff_async(inputs=request.settings)
               output = result.raw if hasattr(result, 'raw') else str(result)
               return PluginResult(plugin_run_id=request.plugin_run_id, status="completed", output=output)
       except asyncio.TimeoutError:
           return PluginResult(plugin_run_id=request.plugin_run_id, status="failed",
                              error=f"Workflow exceeded {self.timeout_seconds}s timeout")
       except Exception as e:
           return PluginResult(plugin_run_id=request.plugin_run_id, status="failed", error=str(e))
       ```
  - `_load_crew(self, plugin_name: str, settings: dict) -> Crew | None` method:
    1. Build path: `Path(self.plugin_dir) / plugin_name / "crew"`
    2. Check if crew directory exists, return None if not
    3. Check for `crew.py` inside crew directory
    4. If crew.py not found, return None (Phase 9 will add actual crew.py in Plan 03)
    5. Dynamic import using importlib: `spec = importlib.util.spec_from_file_location(f"{plugin_name}_crew", crew_path / "crew.py")`, load module, call `module.create_crew(settings)` which returns a Crew instance
    6. On import error: log and return None

The `_load_crew` method uses a convention: each plugin's `crew/crew.py` must export a `create_crew(settings: dict) -> Crew` factory function. This is the contract between sidecar and plugin crews.

Create `sidecar/Dockerfile` with:
- Multi-stage build: `python:3.12-slim` base
- Stage 1 (builder): install `uv`, copy pyproject.toml, run `uv pip install --system .`
- Stage 2 (runtime): copy installed packages from builder, copy sidecar source code, copy plugins directory (for crew definitions)
- Set working directory to `/app/sidecar`
- Expose port 8000
- CMD: `["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "2"]`
- Use `--workers 2` for production (not too many — each worker runs one consumer, and CrewAI workflows are CPU-bound per execution)
- Labels: maintainer, description
  </action>
  <verify>
Verify Python syntax for all files: `python3 -c "import ast; ast.parse(open('sidecar/worker.py').read()); ast.parse(open('sidecar/executor.py').read()); print('Syntax OK')"`. Verify Dockerfile has valid syntax: `grep -c 'FROM\|CMD\|COPY\|RUN\|EXPOSE' sidecar/Dockerfile` should return at least 5 matching lines. Verify stream constants match Go side: `grep 'plugin:requests' sidecar/models.py` and `grep 'plugin:results' sidecar/models.py`.
  </verify>
  <done>worker.py has two-phase consumer loop (pending recovery + new messages) with XACK on success, no-ACK on failure. executor.py has CrewExecutor with asyncio.timeout wrapper and dynamic plugin crew loading via importlib. Dockerfile builds production image with uvicorn multi-worker. Stream constants and message schemas match Go side exactly.</done>
</task>

</tasks>

<verification>
- All Python files pass syntax check (`ast.parse`)
- pyproject.toml is valid TOML with correct dependencies
- Dockerfile has FROM, COPY, CMD directives
- Stream names match Go constants: "plugin:requests" and "plugin:results"
- Consumer group name matches Go constant: "crewai-workers"
- Pydantic PluginRequest fields match Go PluginRequest struct (plugin_run_id, plugin_name, user_id, settings)
- Pydantic PluginResult fields match Go PluginResult struct (plugin_run_id, status, output, error)
- executor.py uses `asyncio.timeout()` (not CrewAI built-in timeout)
- worker.py ACKs after publishing result, does NOT ACK on processing error
- main.py uses separate Redis client for health checks
</verification>

<success_criteria>
- FastAPI sidecar has working health endpoints (/health/live, /health/ready)
- Worker loop consumes from plugin:requests via consumer group with pending recovery
- CrewAI executor wraps kickoff_async with asyncio.timeout for thread-leak safety
- Result published to plugin:results stream after processing
- Dockerfile produces runnable container image
- All message schemas align between Go and Python sides
</success_criteria>

<output>
After completion, create `.planning/phases/09-crewai-sidecar-integration/09-02-SUMMARY.md`
</output>
